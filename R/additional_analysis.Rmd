---
title: 'Using the party as a shield: additional analyses'
output: 
    bookdown::pdf_document2:
      toc: false
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message=FALSE,
                      warning=FALSE)

knitr::read_chunk("data_prep_local.R")
knitr::read_chunk("data_prep.R")
knitr::read_chunk("additional_analysis_R+R.R")
```

```{r set-local-paths, echo=FALSE}

```

```{r read-local-data}

```

```{r process-local-data}

```

```{r setup-additional-analysis}

```


```{r autoresponse-descriptives}

```


#  Holding Responses and Substantive Response Patterns

Reviewer 1 raises a concern that the high levels of holding responses we received may indicate that some MPs suspect that they are part of an experiment and have sent holding responses in order to verify that, and asks why we did not respond 

The purpose of holding emails was generally to acknowledge receipt, but they also often contained other material, frequently letting those who write to MPs know that it may take some time to receive a response. Because of the convention that MPs deal with personal inquiries only from their own constituents, one of the frequent pieces of information in these holding emails was to check that letters included correspondents names and addresses. The holding responses we received were almost exclusively automated response generated by email out-of-office systems. These emails, and any requests to check name and address information, are sent to all those who email the MP the emails. We do not, therefore, think they indicate that some MPs suspect they are part of an experiment.

The frequency with which MPs followed up on holding responses to provide substantive responses gives further reassurance that MPs holding responses do not signal reluctance to engage with the letters we arranged to be sent to MP. Holding responses were generally a prelude to a further more substantive response. In fact `r round(prop_holding_to_substantive*100)` percent of holding responses were followed up with a substantive response. By comparison, just `r round(prop_noholding_to_substantive*100)` percent of letters where no holding response was sent received a substantive response. (We also note that Reviewer 1 states that more than half responses are holding responses but in fact we have more substantive responses that holding responses: we sent `r nrow(main)` letters, there are `r sum(main$autoresponse_exists)` holding responses, whilst there are  `r sum(main$manualresponse_exists_inc_post_count_nonresponse)` substantive responses.) 



# In addition to the analysis of balance in the paper we could have some further assessment of balance 

We could additional assess safe seats (perhaps majority less that 10%, and majority less than 5%).

Gender of MP

Seniority of MP

# Exploratory Non-response Analysis

```{r descriptive-responsiveness-analysis-setup}

```


```{r descriptive-response-analysis}

```

```{r descriptive-response-results-plot, fig.cap="Coefficient plot of linear probability model using largely categorical independent variables, where the dependent variable is whether the letter has a response by either email or post (1) or no recorded response by either email or post (0). The plot includes coeffiecients from models with each potential dependent variable entered separately, and a full model with all potential dependent variables entered together. All models include MP random effects."}

```


```{r descriptive-response-analysis-cont}

```

```{r descriptive-response-results-cont-plot, fig.cap="Coefficient plot of linear probability model using some continuous categorical variables, where the dependent variable is whether the letter has a response by either email or post (1) or no recorded response by either email or post (0). The plot includes coeffiecients from models with each potential dependent variable entered separately, and a full model with all potential dependent variables entered together. All models include MP random effects."}

```

Reviewer 4 says that it might be fun/interesting to examine whether response rate to letters to MPs are associated with things like: MP gender, MP seniority, marginaltiy, est. Brexit Referendum Vote, Party, length of MP service, MP seniority (backbench v frontbench MPs)

We have some data which could be used to answer some of these questions from the BES data (party, gender, marginality, Brexit Referendum vote), it would be good to supplement this with the data on length of MP service, MP frontbench v backbench.

We could examine the association between whether the MP responds or not to our letter in a model with MP random effects. For some variables we have to decide whether to use either use categorical or continuous versions of those variables (e.g. to make identification of the constituencies involved harder - but see discussion below). 

For example we could use a binary version of the party variable: e.g. Conservative v all other parties, use `cut_number` to create categories of the estimated Brexit vote in the constituency. We could also use use a categorical measure of marginality (following the discussion of marginality in the [House of Commons Library insight on paper on marginality](https://commonslibrary.parliament.uk/2024-general-election-marginality/) we could consider constituencies where the result was not very close alongside three categories of marginal, where the winning margin was less than 10%, where the winning margin was less than 5% and where the winning margin was less than 2%).   


The results of some preliminary analysis using categorical versions of variables is shown in Figure \@ref(fig:descriptive-response-results-plot) and a similar analysis using continuous versions of the variables is shown in Figure \@ref(fig:descriptive-response-results-cont-plot). In both cases the results suggest that there is not much relationship between MP response rates and either constituency marginality or with the party of the MP, but that there is an association between response rates and the level of support for leave in the EU referendum.


## Sharing the data for analysis has a high risk of revealing which MPs respond to letters

```{r cases-per-cell-experiment}

```

```{r cases-per-cell-response-experiment}

```

Sharing the data on which the descriptive analysis is based on will deanonymise the response rate information (so people will be able to tell from our data whether particularly MPs responded to the emails we sent them). I think the options available to us are:

  1.  Undertake the analysis but withhold the data and code for this part of the analysis.
  1.  Undertake the analysis and provide replication data and code, on the basis that we think it is acceptable to deanonymise MP response rates.
  1.  Find another option I haven't thought of in the analysis, or in the approach to sharing the data which does not deanonymise the MPs.
  1.  Not undertake this part of the analysis.

I think that my preference is for option 1.

Some further detail on these questions is provided below:

I think we risk deanonymising out data if we with cells to be smaller than about five, and we are very likely to have many cells much smaller than this level. 

From the data we share for the balance analysis it is possible to figure out which constituencies are in our experiment and which constituencies are not in our experiment. I think we agreed that this is acceptable because it reveals information only about our behaviour and not about the individual MPs behaviour. 

It is quite tricky to avoid revealing information about individual MPs responses rates in our exploratory non-response analysis. If we use continuous measures for constituency level variables, then when we share this then just one variable by itself will generally be sufficient to identify the constituency. Categorisation can address that issues with respect to single variables. However, even with very broad categorisation of the data across a three variables the data will effectively allow the users to identify which constituencies particularly when combined with the information about which constituencies are in our experiment. 

For example, as show in Table \ref{tab:cases-per-cell-experiment} even if we create two party categories (Con v All others), three Brexit estimated leave vote categories, and two marginality categories (above/below 10% majority) there are many constituencies that are completely identified (cell size of 1), and most of the cells have fewer than 5 cases.

Separately releasing datasets for each category does not resolve this issue. As shown in Table \ref{tab:cases-per-cell-response-experiment}, just providing the information on response patterns will enable many constituencies to be deterministically linked across the datasets (without even considering the use of the information from the categorisations to supplement this). 

Hence, I don't currently see a way to release information for the descriptive analysis of response rates by constituency and MP characteristics without revealing information about the responsiveness of particular MPs.




